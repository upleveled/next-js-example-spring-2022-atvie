"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const generate_1 = require("@ts-safeql/generate");
const shared_1 = require("@ts-safeql/shared");
const fs_1 = __importDefault(require("fs"));
const path_1 = __importDefault(require("path"));
const postgres_1 = __importDefault(require("postgres"));
const synckit_1 = require("synckit");
const ts_pattern_1 = require("ts-pattern");
const fp_ts_1 = require("../utils/fp-ts");
const pg_utils_1 = require("../utils/pg.utils");
const connections = new Map();
(0, synckit_1.runAsWorker)(async (params) => {
    const result = await (0, fp_ts_1.pipe)(fp_ts_1.TE.Do, fp_ts_1.TE.chain(() => workerHandler(params)))();
    if (params.connection.keepAlive === false) {
        closeConnection(params.connection);
    }
    return fp_ts_1.J.stringify(result);
});
function workerHandler(params) {
    const strategy = mapRuleOptionsToStartegy(params.connection);
    const connnectionPayload = (0, ts_pattern_1.match)(strategy)
        .with({ type: "databaseUrl" }, ({ databaseUrl }) => fp_ts_1.TE.right(getOrCreateConnection(databaseUrl)))
        .with({ type: "migrations" }, ({ migrationsDir, databaseName, connectionUrl }) => {
        const connectionOptions = Object.assign(Object.assign({}, (0, pg_utils_1.parseConnection)(connectionUrl)), { database: databaseName });
        const databaseUrl = (0, pg_utils_1.mapConnectionOptionsToString)(connectionOptions);
        const { sql, isFirst } = getOrCreateConnection(databaseUrl);
        const connectionPayload = { sql, isFirst, databaseUrl };
        if (isFirst) {
            const migrationsPath = path_1.default.join(params.projectDir, migrationsDir);
            return (0, fp_ts_1.pipe)(fp_ts_1.TE.Do, fp_ts_1.TE.chainW(() => (0, pg_utils_1.initDatabase)(connectionOptions)), fp_ts_1.TE.chainW(() => runMigrations({ migrationsPath, sql })), fp_ts_1.TE.map(() => connectionPayload));
        }
        return fp_ts_1.TE.right(connectionPayload);
    })
        .exhaustive();
    const generateTask = (params) => {
        return fp_ts_1.TE.tryCatch(() => {
            return (0, generate_1.generate)(params);
        }, shared_1.InternalError.to);
    };
    return (0, fp_ts_1.pipe)(connnectionPayload, fp_ts_1.TE.chainW(({ sql, databaseUrl }) => {
        return generateTask({
            sql,
            query: params.query,
            cacheKey: databaseUrl,
            pgParsed: params.pgParsed,
            overrides: params.connection.overrides,
            fieldTransform: params.connection.fieldTransform,
        });
    }), fp_ts_1.TE.chainW(fp_ts_1.TE.fromEither));
}
function getOrCreateConnection(databaseUrl) {
    return (0, fp_ts_1.pipe)(fp_ts_1.O.fromNullable(connections.get(databaseUrl)), fp_ts_1.O.foldW(() => {
        const sql = (0, postgres_1.default)(databaseUrl);
        connections.set(databaseUrl, sql);
        return { sql: sql, databaseUrl, isFirst: true };
    }, (sql) => ({ sql, databaseUrl, isFirst: false })));
}
function runMigrations(params) {
    const runSingleMigrationFileWithSql = (filePath) => {
        return runSingleMigrationFile(params.sql, filePath);
    };
    return (0, fp_ts_1.pipe)(fp_ts_1.TE.Do, fp_ts_1.TE.chain(() => getMigrationFiles(params.migrationsPath)), fp_ts_1.TE.chainW((files) => fp_ts_1.TE.sequenceSeqArray(files.map(runSingleMigrationFileWithSql))));
}
function findDeepSqlFiles(migrationsPath) {
    const sqlFilePaths = [];
    function findDeepSqlFilesRecursively(dir) {
        const files = fs_1.default.readdirSync(dir);
        files.forEach((file) => {
            const filePath = path_1.default.join(dir, file);
            const isDirectory = fs_1.default.statSync(filePath).isDirectory();
            if (isDirectory) {
                findDeepSqlFilesRecursively(filePath);
            }
            else if (filePath.endsWith(".sql")) {
                sqlFilePaths.push(filePath);
            }
        });
    }
    findDeepSqlFilesRecursively(migrationsPath);
    return sqlFilePaths;
}
function getMigrationFiles(migrationsPath) {
    return (0, fp_ts_1.pipe)(fp_ts_1.E.tryCatch(() => findDeepSqlFiles(migrationsPath), fp_ts_1.E.toError), fp_ts_1.TE.fromEither, fp_ts_1.TE.mapLeft(shared_1.InvalidMigrationsPathError.fromErrorC(migrationsPath)));
}
function runSingleMigrationFile(sql, filePath) {
    return (0, fp_ts_1.pipe)(fp_ts_1.TE.tryCatch(() => fs_1.default.promises.readFile(filePath).then((x) => x.toString()), fp_ts_1.E.toError), fp_ts_1.TE.chain((content) => fp_ts_1.TE.tryCatch(() => sql.unsafe(content), fp_ts_1.E.toError)), fp_ts_1.TE.mapLeft(shared_1.InvalidMigrationError.fromErrorC(filePath)));
}
function mapRuleOptionsToStartegy(connection) {
    if ("databaseUrl" in connection) {
        return Object.assign({ type: "databaseUrl" }, connection);
    }
    if ("migrationsDir" in connection) {
        const DEFAULT_CONNECTION_URL = "postgres://postgres:postgres@localhost:5432/postgres";
        return Object.assign({ type: "migrations", connectionUrl: DEFAULT_CONNECTION_URL }, connection);
    }
    return (0, ts_pattern_1.match)(connection).exhaustive();
}
function closeConnection(connection) {
    const strategy = mapRuleOptionsToStartegy(connection);
    (0, ts_pattern_1.match)(strategy)
        .with({ type: "databaseUrl" }, ({ databaseUrl }) => {
        const sql = connections.get(databaseUrl);
        if (sql) {
            sql.end();
            connections.delete(databaseUrl);
        }
    })
        .with({ type: "migrations" }, ({ connectionUrl, databaseName }) => {
        const connectionOptions = Object.assign(Object.assign({}, (0, pg_utils_1.parseConnection)(connectionUrl)), { database: databaseName });
        const databaseUrl = (0, pg_utils_1.mapConnectionOptionsToString)(connectionOptions);
        const sql = connections.get(databaseUrl);
        if (sql) {
            sql.end();
            connections.delete(databaseUrl);
        }
    })
        .exhaustive();
}
//# sourceMappingURL=check-sql.worker.js.map